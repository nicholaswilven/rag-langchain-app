{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model_id = os.getenv(\"OPENAI_MODEL_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hikar\\AppData\\Local\\Temp\\ipykernel_15420\\1788008225.py:3: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(\n",
      "c:\\Users\\hikar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: UserWarning: WARNING! api_base is not default parameter.\n",
      "                api_base was transferred to model_kwargs.\n",
      "                Please confirm that api_base is what you intended.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key = openai_api_key,\n",
    "    api_base = openai_api_base,\n",
    "    model_name = openai_model_id,\n",
    "    temperature = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "with open(\"./data/prompts/extract_features.txt\", \"r\") as f:\n",
    "    # Create a LangChain PromptTemplate\n",
    "    extract_features_prompt = ChatPromptTemplate([\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\",  f.read())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'world trade centers',\n",
       " 'price_range': 25.0,\n",
       " 'taste': 'juicy fried chicken'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "query = \"I want juicy fried chicken near world trade centers around 25$\"\n",
    "chain = extract_features_prompt | llm | parser\n",
    "\n",
    "params = chain.invoke({\"query\": query})\n",
    "params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import urllib.parse\n",
    "\n",
    "def get_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)     \n",
    "    return driver \n",
    "\n",
    "def get_coordinates(location, max_retries = 3):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            driver = get_driver()\n",
    "            pattern = r'@(-?\\d+\\.\\d+),(-?\\d+\\.\\d+)'\n",
    "            driver.get(f'https://www.google.com/maps/place/{location.replace(\" \",\"+\")}')\n",
    "            time.sleep(4)\n",
    "            current_url = driver.current_url\n",
    "            matches = re.search(pattern, current_url)\n",
    "            if matches:\n",
    "                latitude = matches.group(1)\n",
    "                longitude = matches.group(2)\n",
    "                result = [latitude, longitude]\n",
    "                retries = max_retries\n",
    "            else:\n",
    "                raise ValueError\n",
    "        except:\n",
    "            retries += 1\n",
    "            if retries == max_retries:\n",
    "                logger.error(f\"Scrape coordinates for {location} failed after retrying {max_retries} times\")\n",
    "        finally:\n",
    "            driver.quit()                \n",
    "            time.sleep(1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-6.1833216', '106.8138496']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = get_coordinates(params['location'])\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hikar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at .\\data\\models\\dunzhang--stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\data\\\\models\\\\dunzhang--stella_en_400M_v5\\\\2_Dense_512\\\\pytorch_model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m emb_model \u001b[38;5;241m=\u001b[39m StellaEmbeddingModel()\n\u001b[0;32m      3\u001b[0m emb_model\u001b[38;5;241m.\u001b[39mdownload_model()\n\u001b[1;32m----> 4\u001b[0m \u001b[43memb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m emb_model\n",
      "File \u001b[1;32md:\\Users\\hikar\\Desktop\\MockupLearning\\rag-langchain-app\\application\\embeddings.py:62\u001b[0m, in \u001b[0;36mStellaEmbeddingModel.load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_dir, trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_linear \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(in_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size, out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_dim)\n\u001b[0;32m     60\u001b[0m vector_linear_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m     k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvector_linear_directory\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mpytorch_model.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     63\u001b[0m }\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_linear\u001b[38;5;241m.\u001b[39mload_state_dict(vector_linear_dict)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvector_linear\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\Users\\hikar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\hikar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\hikar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\data\\\\models\\\\dunzhang--stella_en_400M_v5\\\\2_Dense_512\\\\pytorch_model.bin'"
     ]
    }
   ],
   "source": [
    "from application.embeddings import StellaEmbeddingModel\n",
    "emb_model = StellaEmbeddingModel()\n",
    "emb_model.download_model()\n",
    "emb_model.load_model()\n",
    "emb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Neo4j\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "neo4j_host = os.getenv(\"NEO4J_HOST\")\n",
    "\n",
    "# Custom retriever to include filtering logic based on location, price, and taste\n",
    "class CustomRestaurantRetriever:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def query_menus(self, input_lat, input_long, input_price, input_distance, input_embeddings):\n",
    "        graph_db = Neo4j(url = neo4j_host, auth = (neo4j_username, neo4j_password))\n",
    "        \n",
    "        \"\"\"Query the menus based on price, distance, and embedding similarity.\"\"\"\n",
    "        result = graph_db.run(\n",
    "            \"MATCH (m:Menu)-[:OFFERS]->(r:Restaurant) \"\n",
    "            \"WHERE m.price < $input_price AND \"\n",
    "            \"distance(point(r), point({latitude: $input_lat, longitude: $input_long})) < $input_distance \"\n",
    "            \"RETURN m\",\n",
    "            input_price=input_price,\n",
    "            input_lat=input_lat,\n",
    "            input_long=input_long,\n",
    "            input_distance=input_distance\n",
    "        )\n",
    "\n",
    "        # Filter by cosine similarity\n",
    "        filtered_menus = []\n",
    "        for record in result:\n",
    "            menu = record[\"m\"]\n",
    "            menu_embedding = menu[\"embedding\"]\n",
    "            similarity = self.get_cosine_similarity(menu_embedding, input_embeddings)\n",
    "            if similarity > 0.7:\n",
    "                filtered_menus.append(menu)\n",
    "\n",
    "        return filtered_menus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
